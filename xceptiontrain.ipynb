{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0YBEz670Nnmv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt;\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os as os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir0q0GyfgmSI"
   },
   "source": [
    "# Preparing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load('data_train220.npy')\n",
    "n=220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = np.load('labels_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8443"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2SdFPT6cpAi",
    "outputId": "bbceb15b-9425-42dd-8920-4ff7f39dd900",
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = to_categorical(labels,num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have data and labels as numpy arrays\n",
    "# Shuffle indices\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Shuffle data and labels using the shuffled indices\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8443, 220, 220, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mycutdata=data[7754:-1,:,:,:]\n",
    "mycutlabels=labels[7754:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data=data[0:7753,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels=labels[0:7753]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 04:25:49.466917: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 04:25:50.736957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78911 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "2023-12-06 04:25:50.742248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78911 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "mycutdata = tf.data.Dataset.from_tensor_slices((mycutdata, mycutlabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "buffer_size = len(data)  # Set buffer size as per your dataset size\n",
    "data = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "data = data.shuffle(buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK5tHnEpggbu"
   },
   "source": [
    "# Training The Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    " \n",
    "#lr_scheduler = ReduceLROnPlateau(\n",
    "#    monitor='val_loss',  # You can also use 'val_accuracy' or other metrics\n",
    "#    factor=0.2,           # Factor by which the learning rate will be reduced\n",
    "#    patience=6,          # Number of epochs with no improvement after which learning rate will be reduced\n",
    "#    min_lr=1e-6           # Lower bound on the learning rate\n",
    "#)\n",
    "\n",
    "# Create the Xception base model\n",
    "base_model = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(n, n, 3),\n",
    "    pooling='avg'\n",
    ")\n",
    "base_model.trainable = False\n",
    "x = Flatten()(base_model.output)\n",
    "base_model.trainable = True\n",
    "# Fine-tune only the last few layers\n",
    "fine_tune_at = 100\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#base_model.trainable = True\n",
    "\n",
    "# Fine-tune only the last few layers\n",
    "\n",
    "x = Dense(300, activation='relu')(x)#, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "x=Dropout(0.60)(x)\n",
    "#x = Dense(100, activation='relu')(x)#, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "#x=Dropout(0.52)(x)\n",
    "x = Dense(27, activation='relu')(x)\n",
    "x=Dropout(0.5)(x)\n",
    "outputs = Dense(9, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "xception_model = Model(inputs=base_model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAgSK9fAbp6y",
    "outputId": "a2db2800-fee9-465b-e786-8c276d14c5e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 220, 220, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 109, 109, 32  864         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv1_bn (BatchNormaliz  (None, 109, 109, 32  128        ['block1_conv1[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv1_act (Activation)  (None, 109, 109, 32  0           ['block1_conv1_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 107, 107, 64  18432       ['block1_conv1_act[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2_bn (BatchNormaliz  (None, 107, 107, 64  256        ['block1_conv2[0][0]']           \n",
      " ation)                         )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2_act (Activation)  (None, 107, 107, 64  0           ['block1_conv2_bn[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_sepconv1 (SeparableConv  (None, 107, 107, 12  8768       ['block1_conv2_act[0][0]']       \n",
      " 2D)                            8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv1_bn (BatchNorma  (None, 107, 107, 12  512        ['block2_sepconv1[0][0]']        \n",
      " lization)                      8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv2_act (Activatio  (None, 107, 107, 12  0          ['block2_sepconv1_bn[0][0]']     \n",
      " n)                             8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv2 (SeparableConv  (None, 107, 107, 12  17536      ['block2_sepconv2_act[0][0]']    \n",
      " 2D)                            8)                                                                \n",
      "                                                                                                  \n",
      " block2_sepconv2_bn (BatchNorma  (None, 107, 107, 12  512        ['block2_sepconv2[0][0]']        \n",
      " lization)                      8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 54, 54, 128)  8192        ['block1_conv2_act[0][0]']       \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 54, 54, 128)  0           ['block2_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 54, 54, 128)  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 54, 54, 128)  0           ['block2_pool[0][0]',            \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " block3_sepconv1_act (Activatio  (None, 54, 54, 128)  0          ['add_12[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv1 (SeparableConv  (None, 54, 54, 256)  33920      ['block3_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv1_bn (BatchNorma  (None, 54, 54, 256)  1024       ['block3_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3_sepconv2_act (Activatio  (None, 54, 54, 256)  0          ['block3_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv2 (SeparableConv  (None, 54, 54, 256)  67840      ['block3_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv2_bn (BatchNorma  (None, 54, 54, 256)  1024       ['block3_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 27, 27, 256)  32768       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 27, 27, 256)  0           ['block3_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 27, 27, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 27, 27, 256)  0           ['block3_pool[0][0]',            \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " block4_sepconv1_act (Activatio  (None, 27, 27, 256)  0          ['add_13[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv1 (SeparableConv  (None, 27, 27, 728)  188672     ['block4_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4_sepconv1_bn (BatchNorma  (None, 27, 27, 728)  2912       ['block4_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4_sepconv2_act (Activatio  (None, 27, 27, 728)  0          ['block4_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv2 (SeparableConv  (None, 27, 27, 728)  536536     ['block4_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4_sepconv2_bn (BatchNorma  (None, 27, 27, 728)  2912       ['block4_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 14, 14, 728)  186368      ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 728)  0           ['block4_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 14, 14, 728)  2912       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 14, 14, 728)  0           ['block4_pool[0][0]',            \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " block5_sepconv1_act (Activatio  (None, 14, 14, 728)  0          ['add_14[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv1 (SeparableConv  (None, 14, 14, 728)  536536     ['block5_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv1_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block5_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv2_act (Activatio  (None, 14, 14, 728)  0          ['block5_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv2 (SeparableConv  (None, 14, 14, 728)  536536     ['block5_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv2_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block5_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv3_act (Activatio  (None, 14, 14, 728)  0          ['block5_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv3 (SeparableConv  (None, 14, 14, 728)  536536     ['block5_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv3_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block5_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 14, 14, 728)  0           ['block5_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " block6_sepconv1_act (Activatio  (None, 14, 14, 728)  0          ['add_15[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv1 (SeparableConv  (None, 14, 14, 728)  536536     ['block6_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv1_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block6_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv2_act (Activatio  (None, 14, 14, 728)  0          ['block6_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv2 (SeparableConv  (None, 14, 14, 728)  536536     ['block6_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv2_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block6_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv3_act (Activatio  (None, 14, 14, 728)  0          ['block6_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv3 (SeparableConv  (None, 14, 14, 728)  536536     ['block6_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv3_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block6_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 14, 14, 728)  0           ['block6_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " block7_sepconv1_act (Activatio  (None, 14, 14, 728)  0          ['add_16[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv1 (SeparableConv  (None, 14, 14, 728)  536536     ['block7_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv1_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block7_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv2_act (Activatio  (None, 14, 14, 728)  0          ['block7_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv2 (SeparableConv  (None, 14, 14, 728)  536536     ['block7_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv2_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block7_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv3_act (Activatio  (None, 14, 14, 728)  0          ['block7_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv3 (SeparableConv  (None, 14, 14, 728)  536536     ['block7_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv3_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block7_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 14, 14, 728)  0           ['block7_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " block8_sepconv1_act (Activatio  (None, 14, 14, 728)  0          ['add_17[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv1 (SeparableConv  (None, 14, 14, 728)  536536     ['block8_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv1_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block8_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv2_act (Activatio  (None, 14, 14, 728)  0          ['block8_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv2 (SeparableConv  (None, 14, 14, 728)  536536     ['block8_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv2_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block8_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv3_act (Activatio  (None, 14, 14, 728)  0          ['block8_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv3 (SeparableConv  (None, 14, 14, 728)  536536     ['block8_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv3_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block8_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 14, 14, 728)  0           ['block8_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " block9_sepconv1_act (Activatio  (None, 14, 14, 728)  0          ['add_18[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv1 (SeparableConv  (None, 14, 14, 728)  536536     ['block9_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv1_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block9_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv2_act (Activatio  (None, 14, 14, 728)  0          ['block9_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv2 (SeparableConv  (None, 14, 14, 728)  536536     ['block9_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv2_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block9_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv3_act (Activatio  (None, 14, 14, 728)  0          ['block9_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv3 (SeparableConv  (None, 14, 14, 728)  536536     ['block9_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv3_bn (BatchNorma  (None, 14, 14, 728)  2912       ['block9_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 14, 14, 728)  0           ['block9_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " block10_sepconv1_act (Activati  (None, 14, 14, 728)  0          ['add_19[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv1 (SeparableCon  (None, 14, 14, 728)  536536     ['block10_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv1_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block10_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv2_act (Activati  (None, 14, 14, 728)  0          ['block10_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv2 (SeparableCon  (None, 14, 14, 728)  536536     ['block10_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv2_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block10_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv3_act (Activati  (None, 14, 14, 728)  0          ['block10_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv3 (SeparableCon  (None, 14, 14, 728)  536536     ['block10_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv3_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block10_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 14, 14, 728)  0           ['block10_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " block11_sepconv1_act (Activati  (None, 14, 14, 728)  0          ['add_20[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv1 (SeparableCon  (None, 14, 14, 728)  536536     ['block11_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv1_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block11_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv2_act (Activati  (None, 14, 14, 728)  0          ['block11_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv2 (SeparableCon  (None, 14, 14, 728)  536536     ['block11_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv2_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block11_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv3_act (Activati  (None, 14, 14, 728)  0          ['block11_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv3 (SeparableCon  (None, 14, 14, 728)  536536     ['block11_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv3_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block11_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 14, 14, 728)  0           ['block11_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " block12_sepconv1_act (Activati  (None, 14, 14, 728)  0          ['add_21[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv1 (SeparableCon  (None, 14, 14, 728)  536536     ['block12_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv1_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block12_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block12_sepconv2_act (Activati  (None, 14, 14, 728)  0          ['block12_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv2 (SeparableCon  (None, 14, 14, 728)  536536     ['block12_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv2_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block12_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block12_sepconv3_act (Activati  (None, 14, 14, 728)  0          ['block12_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv3 (SeparableCon  (None, 14, 14, 728)  536536     ['block12_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv3_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block12_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 14, 14, 728)  0           ['block12_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " block13_sepconv1_act (Activati  (None, 14, 14, 728)  0          ['add_22[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv1 (SeparableCon  (None, 14, 14, 728)  536536     ['block13_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block13_sepconv1_bn (BatchNorm  (None, 14, 14, 728)  2912       ['block13_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block13_sepconv2_act (Activati  (None, 14, 14, 728)  0          ['block13_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv2 (SeparableCon  (None, 14, 14, 1024  752024     ['block13_sepconv2_act[0][0]']   \n",
      " v2D)                           )                                                                 \n",
      "                                                                                                  \n",
      " block13_sepconv2_bn (BatchNorm  (None, 14, 14, 1024  4096       ['block13_sepconv2[0][0]']       \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 7, 7, 1024)   745472      ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " block13_pool (MaxPooling2D)    (None, 7, 7, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 7, 1024)  4096        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 7, 7, 1024)   0           ['block13_pool[0][0]',           \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " block14_sepconv1 (SeparableCon  (None, 7, 7, 1536)  1582080     ['add_23[0][0]']                 \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv1_bn (BatchNorm  (None, 7, 7, 1536)  6144        ['block14_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv1_act (Activati  (None, 7, 7, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block14_sepconv2 (SeparableCon  (None, 7, 7, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv2_bn (BatchNorm  (None, 7, 7, 2048)  8192        ['block14_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv2_act (Activati  (None, 7, 7, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2048)         0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 300)          614700      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 300)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 27)           8127        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 27)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 9)            252         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,484,559\n",
      "Trainable params: 10,101,423\n",
      "Non-trainable params: 11,383,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPCJsk68dm40",
    "outputId": "2c2d9d48-234c-4317-d64e-3cf298628979",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Nadam\n",
    "optimizer = Nadam(learning_rate=0.0001, beta_1=0.96, beta_2=0.998)\n",
    "xception_model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "107/107 [==============================] - ETA: 0s - loss: 2.0402 - accuracy: 0.2141\n",
      "Epoch 00001: val_loss improved from inf to 1.33564, saving model to best_weights7.h5\n",
      "107/107 [==============================] - 13s 85ms/step - loss: 2.0402 - accuracy: 0.2141 - val_loss: 1.3356 - val_accuracy: 0.5843\n",
      "Epoch 2/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 1.1428 - accuracy: 0.5956\n",
      "Epoch 00002: val_loss improved from 1.33564 to 0.45047, saving model to best_weights7.h5\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 1.1417 - accuracy: 0.5962 - val_loss: 0.4505 - val_accuracy: 0.8823\n",
      "Epoch 3/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.6683 - accuracy: 0.7643\n",
      "Epoch 00003: val_loss improved from 0.45047 to 0.24926, saving model to best_weights7.h5\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 0.6696 - accuracy: 0.7636 - val_loss: 0.2493 - val_accuracy: 0.9404\n",
      "Epoch 4/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.8263\n",
      "Epoch 00004: val_loss improved from 0.24926 to 0.17446, saving model to best_weights7.h5\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 0.4717 - accuracy: 0.8260 - val_loss: 0.1745 - val_accuracy: 0.9535\n",
      "Epoch 5/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8624\n",
      "Epoch 00005: val_loss did not improve from 0.17446\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.3737 - accuracy: 0.8621 - val_loss: 0.2057 - val_accuracy: 0.9404\n",
      "Epoch 6/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.8890\n",
      "Epoch 00006: val_loss did not improve from 0.17446\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.2964 - accuracy: 0.8889 - val_loss: 0.1918 - val_accuracy: 0.9535\n",
      "Epoch 7/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.9064\n",
      "Epoch 00007: val_loss did not improve from 0.17446\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.2434 - accuracy: 0.9065 - val_loss: 0.1848 - val_accuracy: 0.9622\n",
      "Epoch 8/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.9261\n",
      "Epoch 00008: val_loss did not improve from 0.17446\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1998 - accuracy: 0.9260 - val_loss: 0.1913 - val_accuracy: 0.9549\n",
      "Epoch 9/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9293\n",
      "Epoch 00009: val_loss did not improve from 0.17446\n",
      "107/107 [==============================] - 8s 71ms/step - loss: 0.1890 - accuracy: 0.9293 - val_loss: 0.1962 - val_accuracy: 0.9578\n",
      "Epoch 10/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9422\n",
      "Epoch 00010: val_loss did not improve from 0.17446\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1598 - accuracy: 0.9421 - val_loss: 0.2257 - val_accuracy: 0.9608\n",
      "Epoch 11/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1455 - accuracy: 0.9440\n",
      "Epoch 00011: val_loss improved from 0.17446 to 0.16306, saving model to best_weights7.h5\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 0.1458 - accuracy: 0.9440 - val_loss: 0.1631 - val_accuracy: 0.9680\n",
      "Epoch 12/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1329 - accuracy: 0.9514\n",
      "Epoch 00012: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1331 - accuracy: 0.9512 - val_loss: 0.1799 - val_accuracy: 0.9695\n",
      "Epoch 13/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9528\n",
      "Epoch 00013: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1282 - accuracy: 0.9529 - val_loss: 0.1702 - val_accuracy: 0.9724\n",
      "Epoch 14/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9544\n",
      "Epoch 00014: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1160 - accuracy: 0.9543 - val_loss: 0.2789 - val_accuracy: 0.9593\n",
      "Epoch 15/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9546\n",
      "Epoch 00015: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1167 - accuracy: 0.9547 - val_loss: 0.2459 - val_accuracy: 0.9593\n",
      "Epoch 16/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9592\n",
      "Epoch 00016: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1125 - accuracy: 0.9590 - val_loss: 0.1974 - val_accuracy: 0.9695\n",
      "Epoch 17/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9550\n",
      "Epoch 00017: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1161 - accuracy: 0.9550 - val_loss: 0.2464 - val_accuracy: 0.9622\n",
      "Epoch 18/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9632\n",
      "Epoch 00018: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1015 - accuracy: 0.9631 - val_loss: 0.2358 - val_accuracy: 0.9680\n",
      "Epoch 19/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9621\n",
      "Epoch 00019: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0948 - accuracy: 0.9620 - val_loss: 0.2435 - val_accuracy: 0.9680\n",
      "Epoch 20/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9602\n",
      "Epoch 00020: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0943 - accuracy: 0.9601 - val_loss: 0.2145 - val_accuracy: 0.9724\n",
      "Epoch 21/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 0.9651\n",
      "Epoch 00021: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0892 - accuracy: 0.9649 - val_loss: 0.2000 - val_accuracy: 0.9724\n",
      "Epoch 22/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9641\n",
      "Epoch 00022: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0930 - accuracy: 0.9638 - val_loss: 0.2229 - val_accuracy: 0.9695\n",
      "Epoch 23/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9672\n",
      "Epoch 00023: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0831 - accuracy: 0.9669 - val_loss: 0.2138 - val_accuracy: 0.9738\n",
      "Epoch 24/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0864 - accuracy: 0.9678\n",
      "Epoch 00024: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0864 - accuracy: 0.9678 - val_loss: 0.2553 - val_accuracy: 0.9637\n",
      "Epoch 25/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9732\n",
      "Epoch 00025: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0788 - accuracy: 0.9733 - val_loss: 0.2239 - val_accuracy: 0.9680\n",
      "Epoch 26/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9692\n",
      "Epoch 00026: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0920 - accuracy: 0.9692 - val_loss: 0.2960 - val_accuracy: 0.9622\n",
      "Epoch 27/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9730\n",
      "Epoch 00027: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0736 - accuracy: 0.9730 - val_loss: 0.1976 - val_accuracy: 0.9651\n",
      "Epoch 28/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9712\n",
      "Epoch 00028: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0698 - accuracy: 0.9712 - val_loss: 0.2237 - val_accuracy: 0.9680\n",
      "Epoch 29/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9756\n",
      "Epoch 00029: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0647 - accuracy: 0.9754 - val_loss: 0.2572 - val_accuracy: 0.9695\n",
      "Epoch 30/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9734\n",
      "Epoch 00030: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0712 - accuracy: 0.9733 - val_loss: 0.2841 - val_accuracy: 0.9709\n",
      "Epoch 31/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 0.9732\n",
      "Epoch 00031: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0687 - accuracy: 0.9732 - val_loss: 0.3509 - val_accuracy: 0.9622\n",
      "Epoch 32/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9712\n",
      "Epoch 00032: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0778 - accuracy: 0.9712 - val_loss: 0.2060 - val_accuracy: 0.9753\n",
      "Epoch 33/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9762\n",
      "Epoch 00033: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0637 - accuracy: 0.9763 - val_loss: 0.2755 - val_accuracy: 0.9666\n",
      "Epoch 34/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9782\n",
      "Epoch 00034: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0568 - accuracy: 0.9781 - val_loss: 0.2909 - val_accuracy: 0.9666\n",
      "Epoch 35/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9774\n",
      "Epoch 00035: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 71ms/step - loss: 0.0578 - accuracy: 0.9773 - val_loss: 0.2260 - val_accuracy: 0.9724\n",
      "Epoch 36/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9782\n",
      "Epoch 00036: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 71ms/step - loss: 0.0577 - accuracy: 0.9781 - val_loss: 0.2730 - val_accuracy: 0.9695\n",
      "Epoch 37/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9732\n",
      "Epoch 00037: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0693 - accuracy: 0.9733 - val_loss: 0.3142 - val_accuracy: 0.9637\n",
      "Epoch 38/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 0.9762\n",
      "Epoch 00038: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0616 - accuracy: 0.9763 - val_loss: 0.2357 - val_accuracy: 0.9724\n",
      "Epoch 39/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9792\n",
      "Epoch 00039: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 0.2440 - val_accuracy: 0.9709\n",
      "Epoch 40/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9804\n",
      "Epoch 00040: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0522 - accuracy: 0.9803 - val_loss: 0.2632 - val_accuracy: 0.9680\n",
      "Epoch 41/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9748\n",
      "Epoch 00041: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0772 - accuracy: 0.9748 - val_loss: 0.2114 - val_accuracy: 0.9680\n",
      "Epoch 42/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9797\n",
      "Epoch 00042: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0564 - accuracy: 0.9797 - val_loss: 0.1822 - val_accuracy: 0.9782\n",
      "Epoch 43/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9776\n",
      "Epoch 00043: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0569 - accuracy: 0.9774 - val_loss: 0.1929 - val_accuracy: 0.9753\n",
      "Epoch 44/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0668 - accuracy: 0.9774\n",
      "Epoch 00044: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 0.2155 - val_accuracy: 0.9709\n",
      "Epoch 45/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9780\n",
      "Epoch 00045: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0610 - accuracy: 0.9781 - val_loss: 0.2070 - val_accuracy: 0.9724\n",
      "Epoch 46/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9800\n",
      "Epoch 00046: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0538 - accuracy: 0.9800 - val_loss: 0.1836 - val_accuracy: 0.9767\n",
      "Epoch 47/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9788\n",
      "Epoch 00047: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0537 - accuracy: 0.9788 - val_loss: 0.3160 - val_accuracy: 0.9651\n",
      "Epoch 48/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9801\n",
      "Epoch 00048: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.2506 - val_accuracy: 0.9724\n",
      "Epoch 49/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9832\n",
      "Epoch 00049: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.2915 - val_accuracy: 0.9695\n",
      "Epoch 50/50\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9818\n",
      "Epoch 00050: val_loss did not improve from 0.16306\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.0507 - accuracy: 0.9818 - val_loss: 0.2588 - val_accuracy: 0.9738\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# Define a checkpoint callback\n",
    "checkpoint_path = 'best_weights7.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                             monitor='val_loss',  # Monitor validation loss\n",
    "                             save_best_only=True,  # Save only the best model\n",
    "                             mode='min',  # Save when validation loss improves\n",
    "                             verbose=1)  # Show messages about the saving process\n",
    "epochs=50\n",
    "batch_size = 73\n",
    "# Train the model with the callback\n",
    "history = xception_model.fit(data.batch(batch_size),\n",
    "                             epochs=epochs,\n",
    "                             validation_data=mycutdata.batch(batch_size),\n",
    "                             callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# cheking the effect of threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with threshold 0.8: 0.9680232558139535\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.8  # Define your threshold value\n",
    "\n",
    "# Evaluate the model while applying the threshold\n",
    "total_samples = 0\n",
    "correct_samples = 0\n",
    "\n",
    "for batch in mycutdata.batch(batch_size):\n",
    "    images, labels = batch\n",
    "    predictions = xception_model.predict(images)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        predicted_class = np.argmax(predictions[i])\n",
    "        max_probability = np.max(predictions[i])\n",
    "\n",
    "        if max_probability >= threshold:\n",
    "            total_samples += 1\n",
    "            if predicted_class == np.argmax(labels[i]):\n",
    "                correct_samples += 1\n",
    "        else:\n",
    "            # If prediction is uncertain, mark it as mislabeled\n",
    "            total_samples += 1\n",
    "\n",
    "accuracy_with_threshold = correct_samples / total_samples if total_samples > 0 else 0\n",
    "\n",
    "print(f\"Accuracy with threshold {threshold}: {accuracy_with_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggs5y5NcgcAH"
   },
   "source": [
    "# Evaluating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "vAjGo1SvePCE",
    "outputId": "32bfd363-8d7d-4233-eb3d-37a94cbc8ad0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.gcf()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "rEUy8LNOeCVF",
    "outputId": "d697bf6d-4c44-4011-873a-7b38838c39c9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNet-50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
